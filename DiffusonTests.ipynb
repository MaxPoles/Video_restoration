{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f682eb7d-5187-4118-9186-f73e024526f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import ignite.metrics as ig\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73eff209-7f69-4dda-b266-fdfdf1b53e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "teach_im_count = 160\n",
    "batch_size = 8\n",
    "begin_offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c621ab-4701-4ac6-92a5-8b0adef9a23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 420, 420, 3)\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'Record_1'\n",
    "\n",
    "# Получите список файлов в папке\n",
    "image_files = [f for f in os.listdir(folder_path) if f.endswith('.png')]\n",
    "\n",
    "# Инициализируйте список для хранения массивов изображений\n",
    "image_arrays = []\n",
    "# Загрузите каждое изображение, преобразуйте его в массив и добавьте в список\n",
    "for i, image_file in enumerate(image_files):\n",
    "    image_path = os.path.join(folder_path, image_file)\n",
    "    if i >= begin_offset:\n",
    "        with Image.open(image_path) as img:\n",
    "            image_array = np.array(img)\n",
    "            image_arrays.append(image_array)\n",
    "    if i == teach_im_count + begin_offset - 1:\n",
    "        break\n",
    "# Преобразуйте список массивов в один numpy массив\n",
    "record_array = np.array(image_arrays)\n",
    "\n",
    "print(record_array.shape)\n",
    "\n",
    "class OneImDataset(Dataset):\n",
    "    def __init__(self, x_arr):\n",
    "        self.transform1 = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        self.x = x_arr\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.transform1(self.x[idx])\n",
    "        return x\n",
    "        \n",
    "dataset = OneImDataset(record_array)\n",
    "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "record_array = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "044e9b36-b8ea-42ef-9930-d088a7554172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_layer(images, size):\n",
    "    f, axes = plt.subplots(1, size, figsize = (30, 10))\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        image = images[i].detach().numpy()\n",
    "        image = image.transpose((1, 2, 0))\n",
    "        ax.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "938b960e-bb8f-4138-aa27-c81b33791b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_to_im(tensor):\n",
    "    return(tensor.cpu().detach().numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02875503-887d-4d1a-9c75-cb62a1fb347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_real(orig, record, real, size):\n",
    "\n",
    "  f, axes = plt.subplots(3, size, figsize = (30, 16))\n",
    "  for i, ax in enumerate(axes.ravel()):\n",
    "    if i < size:\n",
    "        image = orig[i].detach().numpy()\n",
    "        image = image.transpose((1, 2, 0))\n",
    "        ax.imshow(image)\n",
    "    elif i < 2 * size:\n",
    "        image = record[i - size].detach().numpy()\n",
    "        image = image.transpose((1, 2, 0))\n",
    "        ax.imshow(image)\n",
    "    else:\n",
    "        image = real[i - 2 * size].detach().numpy()\n",
    "        image = image.transpose((1, 2, 0))\n",
    "        ax.imshow(image)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5059c682-0f18-4bdf-9993-1f3c632e734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_all(images, col_count, size):\n",
    "  l = size // col_count\n",
    "  f, axes = plt.subplots(l, col_count, figsize = (30, 9 * l))\n",
    "  for i, ax in enumerate(axes.ravel()):\n",
    "    ax.imshow(t_to_im(images[i]))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d312ed5-9d39-497d-b872-eb6ff4aaf4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_linear1(image, t, T):\n",
    "    beta_0 = 0.0001\n",
    "    beta_T = 0.02\n",
    "    betas = np.linspace(beta_0, beta_T, T)\n",
    "    alpha = np.prod(1 - betas[0:t])\n",
    "    alpha = alpha\n",
    "    noise = torch.randn_like(image)\n",
    "    noisy_image = alpha ** 0.5 * image + (1 - alpha) ** 0.5 * noise\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9370e57-e8a5-40c9-b8b4-35da0193a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_trig(image, t, T):\n",
    "    beta_0 = 0.02\n",
    "    beta_T = 1\n",
    "    start_angle = np.arccos(beta_T)\n",
    "    end_angle = np.arccos(beta_0)\n",
    "    angle = start_angle +  t / T * (end_angle - start_angle)\n",
    "    noise = torch.randn_like(image)\n",
    "    noisy_image = np.cos(angle) * image + np.sin(angle) * noise\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bea2cff1-179d-43fb-9b35-21ee96ac2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "for batch in dataloader:\n",
    "    x = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b965ad5-7499-4126-a1dc-538b0cc28174",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1702d753-3c18-4011-bdcc-3c6a02cd6ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 420, 420])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a188c49f-0d3b-4bc5-b588-14ed1fe66ddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im_array = []\n",
    "T = 100\n",
    "for i in range(T):\n",
    "    im_array.append(add_noise_linear1(image, i, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5e0de-4a84-434d-8f9c-ea030095c676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_images_all(im_array, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b5a8c91-0cb9-4933-b300-0416458cec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_array = []\n",
    "T = 100\n",
    "for i in range(T):\n",
    "    im_array.append(add_noise_trig(image, i, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f557cbb-669f-49c8-b491-a8bc59e229d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_images_all(im_array, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc888223-bb72-4a52-97a1-e6f9d3b50a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding(timesteps, dim):\n",
    "    half_dim = dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = timesteps[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfa8305a-1e04-4a7a-8b70-db32a6af81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95bbba64-2d75-4408-97be-c0dcda21dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = sinusoidal_embedding(t, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47cb0d63-c6f7-4800-be13-c20bae528a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2124, 0.4290, 0.6410, 0.9734, 0.6906, 0.4237, 0.1744, 0.4501])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0210c4e5-77b5-41c8-9042-3806f299af87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 320])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9edfb89c-9e8d-4945-9ab2-acd2c7a676ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 320, 1, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[:,:,None,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccff69c6-84d3-4fec-a20c-3363a95b82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn((8, 3, 420, 420))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ffe699e9-bd22-40a3-ac08-9541f3ebc608",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (320) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t \u001b[38;5;241m+\u001b[39m emb[:,:,\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (320) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "t + emb[:,:,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4745f8b-42d8-49ca-8308-abbe44d6b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "      return x * torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4d543c2-41a6-4a13-9515-b70bc962a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "     def __init__(self, n_channels: int):\n",
    "         super().__init__()\n",
    "         self.n_channels = n_channels\n",
    "         self.lin1 = nn.Linear(self.n_channels // 4, self.n_channels)\n",
    "         self.act = Swish()\n",
    "         self.lin2 = nn.Linear(self.n_channels, self.n_channels)\n",
    "     def forward(self, t: torch.Tensor):\n",
    "          half_dim = self.n_channels // 8\n",
    "          emb = math.log(10_000) / (half_dim - 1)\n",
    "          emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "          emb = t[:, None] * emb[None, :]\n",
    "          emb = torch.cat((emb.sin(), emb.cos()), dim=1)\n",
    "\n",
    "          emb = self.act(self.lin1(emb))\n",
    "          emb = self.lin2(emb)\n",
    "          return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "271001df-77c6-4569-8b10-dcfffd61d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(in_channels1, in_channels2, in_channels3, out_channels, ks1, ks2, ks3, size):\n",
    "    block = nn.Sequential(\n",
    "        nn.Conv2d(in_channels = in_channels1, out_channels = in_channels2, kernel_size = ks1, padding = 0),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = in_channels2, out_channels = in_channels2, kernel_size = ks2, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        #nn.BatchNorm2d(in_channels2),\n",
    "        nn.Conv2d(in_channels = in_channels2, out_channels = in_channels3, kernel_size = 5, padding = 2),\n",
    "        nn.ReLU(),\n",
    "        #nn.BatchNorm2d(in_channels3),\n",
    "        nn.Conv2d(in_channels = in_channels2, out_channels = in_channels3, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = in_channels3, out_channels = out_channels, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = in_channels3, out_channels = out_channels, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        #nn.BatchNorm2d(out_channels),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU()\n",
    "        #nn.BatchNorm2d(out_channels)\n",
    "    )\n",
    "\n",
    "    return block\n",
    "    \n",
    "def upsample_without_batchnorm(in_channels1, in_channels2, in_channels3, out_channels, ks1, ks2, ks3, scale, size):\n",
    "    block = nn.Sequential(\n",
    "        nn.Upsample(size = size),\n",
    "        nn.Conv2d(in_channels = in_channels1, out_channels = in_channels2, kernel_size = ks1, padding = 0),\n",
    "        nn.ReLU(),\n",
    "        #nn.BatchNorm2d(in_channels2),\n",
    "        nn.Conv2d(in_channels = in_channels2, out_channels = in_channels2, kernel_size = ks2, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = in_channels2, out_channels = in_channels2, kernel_size = 5, padding = 2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = in_channels2, out_channels = in_channels2, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = in_channels2, out_channels = in_channels2, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = in_channels2, out_channels = in_channels2, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "\n",
    "    return block\n",
    "\n",
    "ch_size = [3, 32, 64, 128, 256, 512]\n",
    "\n",
    "class Model8(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time_emb1 = TimeEmbedding(3)\n",
    "        self.c1 = compress(ch_size[0], ch_size[1], ch_size[1], ch_size[1], 1, 3, 3, 420) #420 -> 210\n",
    "        self.time_emb2 = TimeEmbedding(32)\n",
    "        self.c2 = compress(ch_size[1], ch_size[2], ch_size[2], ch_size[2], 1, 5, 3, 208) #210 -> 104\n",
    "        self.time_emb3 = TimeEmbedding(64)\n",
    "        self.c3 = compress(ch_size[2], ch_size[3], ch_size[3], ch_size[3], 1, 3, 3, 208) #104 -> 52\n",
    "        self.time_emb4 = TimeEmbedding(128)\n",
    "        self.c4 = compress(ch_size[3], ch_size[4], ch_size[4], ch_size[4], 1, 3, 2, 208) #52 -> 26\n",
    "        self.time_emb5 = TimeEmbedding(256)\n",
    "        self.c5 = compress(ch_size[4], ch_size[5], ch_size[5], ch_size[5], 1, 3, 2, 208) #26 -> 13\n",
    "\n",
    "        \n",
    "        self.d1 = upsample_without_batchnorm(ch_size[5], ch_size[5], ch_size[5], ch_size[4], 1, 3, 3, 2.5, 26)\n",
    "        self.d2 = upsample_without_batchnorm(3 * ch_size[4], ch_size[4], ch_size[4], ch_size[3], 1, 3, 3, 2.5, 52) #23 -> 53 -> 49 2.31\n",
    "        self.d3 = upsample_without_batchnorm(3 * ch_size[3], ch_size[3], ch_size[3], ch_size[2], 1, 3, 3, 2.18, 104) #49 -> 106 -> 102\n",
    "        self.d4 = upsample_without_batchnorm(3 * ch_size[2], ch_size[2], ch_size[2], ch_size[1], 1, 3, 3, 2.08, 210) #102 -> 212 -> 208\n",
    "        self.d5 = upsample_without_batchnorm(3 * ch_size[1], ch_size[1], ch_size[1], ch_size[0], 1, 3, 3, 2.04, 420) #208 -> 424 -> 420\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        x += self.time_emb1(F.relu(t))[:, :, None, None]\n",
    "        x = self.c1(x)\n",
    "        x1 = x\n",
    "        x += self.time_emb2(F.relu(t))[:, :, None, None]\n",
    "        x = self.c2(x)\n",
    "        x2 = x\n",
    "\n",
    "        x += self.time_emb3(F.relu(t))[:, :, None, None]\n",
    "        x = self.c3(x)\n",
    "        x3 = x\n",
    "\n",
    "        x += self.time_emb4(F.relu(t))[:, :, None, None]\n",
    "        x = self.c4(x)\n",
    "        x4 = x\n",
    "        print(f'x1: {x1.shape}')\n",
    "        print(f'x2: {x2.shape}')\n",
    "        print(f'x3: {x3.shape}')\n",
    "        print(f'x4: {x4.shape}')\n",
    "        print(x.shape)\n",
    "        \n",
    "        x += self.time_emb5(F.relu(t))[:, :, None, None]\n",
    "        x = self.c5(x)\n",
    "        print(x.shape)\n",
    "        x = self.d1(x)\n",
    "        x = torch.cat((x, x4), 1)\n",
    "        print(x.shape)\n",
    "        x = self.d2(x)\n",
    "        x = torch.cat((x, x3), 1)\n",
    "        #print(x.shape)\n",
    "        x  = self.d3(x)\n",
    "        x = torch.cat((x, x2), 1)\n",
    "\n",
    "        x = self.d4(x)\n",
    "        x = torch.cat((x, x1), 1)\n",
    "\n",
    "        x = self.d5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5abbf1c-9834-4777-ae0c-17f85fa14640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(in_channels ,out_channels):\n",
    "    block = nn.Sequential(\n",
    "        nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = out_channels, out_channels = out_channels, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = out_channels, out_channels = out_channels, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    return block\n",
    "\n",
    "def time_emb(size, channels):\n",
    "    block = nn.Sequential(\n",
    "        nn.Linear(1, size ** 2 * channels),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(size ** 2 * channels, size ** 2 * channels),\n",
    "        nn.Tanh()\n",
    "    )\n",
    "    return block\n",
    "\n",
    "\n",
    "\n",
    "class DifUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ch = [3, 32, 64, 128, 256, 512, 1024]\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.up = nn.Upsample(scale_factor = 2)\n",
    "        \n",
    "        self.c1 = conv(ch[0], ch[1])\n",
    "        self.c2 = conv(ch[1], ch[2])\n",
    "        self.c3 = conv(ch[2], ch[3])\n",
    "        self.c4 = conv(ch[3], ch[4])\n",
    "        self.c5 = conv(ch[4], ch[5])\n",
    "        self.c6 = conv(ch[5], ch[6])\n",
    "\n",
    "        self.emb = time_emb(10, 3)\n",
    "\n",
    "        self.cc1 = conv(3 + ch[6], ch[5])\n",
    "        self.cc2 = conv(2 * ch[5], ch[4])\n",
    "        self.cc3 = conv(2 * ch[4], ch[3])\n",
    "        self.cc4 = conv(2 * ch[3], ch[2])\n",
    "        self.cc5 = conv(2 * ch[2], ch[1])\n",
    "        self.cc6 = conv(2 * ch[1], ch[0])\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        x = self.c1(x)\n",
    "        x5 = x\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c2(x)\n",
    "        x4 = x\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c3(x)\n",
    "        x3 = x\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c4(x)\n",
    "        x2 = x\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c5(x)\n",
    "        x1 = x\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c6(x)\n",
    "        t = self.emb(t.to(torch.float32))\n",
    "        t = t.view(-1, 3, 10, 10)\n",
    "        x = torch.cat((t, x), dim = 1)\n",
    "        \n",
    "        x = self.cc1(x)\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = torch.cat((x1, x), dim = 1)\n",
    "        x = self.cc2(x)\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = torch.cat((x2, x), dim = 1)\n",
    "        x = self.cc3(x)\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = torch.cat((x3, x), dim = 1)\n",
    "        x = self.cc4(x)\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = torch.cat((x4, x), dim = 1)\n",
    "        x = self.cc5(x)\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = torch.cat((x5, x), dim = 1)\n",
    "        x = self.cc6(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a784d88-0b50-40a2-8711-7d94c4dbe103",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand((8,3,420, 420))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2f1621a-bbc4-4796-8a1b-6f88b9e4382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = torch.tensor([16]*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0d2cf515-a790-429c-8acf-dda20d6da18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = Model8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed795845-d79c-4f80-9967-418a34796b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "md = Model8()\n",
    "md(tensor, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88e766-b11c-4540-a0ac-ec1baff62df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
